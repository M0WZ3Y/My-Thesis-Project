{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PJM Electricity Price Prediction Analysis\n",
    "\n",
    "This notebook provides an interactive interface for analyzing PJM electricity price data and building prediction models for daily and hourly forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PJM data\n",
    "print(\"Loading PJM data...\")\n",
    "data_file = 'da_hrl_lmps (1).csv'\n",
    "\n",
    "# Load data in chunks to handle large file\n",
    "chunks = []\n",
    "for chunk in pd.read_csv(data_file, chunksize=100000):\n",
    "    chunks.append(chunk)\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "# Convert datetime columns\n",
    "df['datetime_beginning_utc'] = pd.to_datetime(df['datetime_beginning_utc'])\n",
    "df['datetime_beginning_ept'] = pd.to_datetime(df['datetime_beginning_ept'])\n",
    "\n",
    "print(f\"Data loaded: {len(df):,} records\")\n",
    "print(f\"Date range: {df['datetime_beginning_utc'].min()} to {df['datetime_beginning_utc'].max()}\")\n",
    "print(f\"Number of unique nodes: {df['pnode_id'].nunique():,}\")\n",
    "print(f\"Number of zones: {df['zone'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "print(\"\\n=== PRICE STATISTICS ===\")\n",
    "print(df['total_lmp_da'].describe())\n",
    "\n",
    "# Zone analysis\n",
    "print(\"\\n=== TOP 10 ZONES BY AVERAGE PRICE ===\")\n",
    "zone_stats = df.groupby('zone')['total_lmp_da'].agg(['mean', 'std', 'count']).round(2)\n",
    "print(zone_stats.sort_values('mean', ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Visualize Price Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time-based features for visualization\n",
    "df['hour'] = df['datetime_beginning_utc'].dt.hour\n",
    "df['day_of_week'] = df['datetime_beginning_utc'].dt.dayofweek\n",
    "df['month'] = df['datetime_beginning_utc'].dt.month\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Hourly pattern\n",
    "hourly_avg = df.groupby('hour')['total_lmp_da'].mean()\n",
    "axes[0, 0].plot(hourly_avg.index, hourly_avg.values, marker='o')\n",
    "axes[0, 0].set_title('Average Price by Hour of Day')\n",
    "axes[0, 0].set_xlabel('Hour')\n",
    "axes[0, 0].set_ylabel('Price ($/MWh)')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Daily pattern\n",
    "daily_avg = df.groupby('day_of_week')['total_lmp_da'].mean()\n",
    "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "axes[0, 1].bar(range(7), daily_avg.values)\n",
    "axes[0, 1].set_title('Average Price by Day of Week')\n",
    "axes[0, 1].set_xlabel('Day of Week')\n",
    "axes[0, 1].set_ylabel('Price ($/MWh)')\n",
    "axes[0, 1].set_xticks(range(7))\n",
    "axes[0, 1].set_xticklabels(days)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Monthly pattern\n",
    "monthly_avg = df.groupby('month')['total_lmp_da'].mean()\n",
    "axes[1, 0].plot(monthly_avg.index, monthly_avg.values, marker='o')\n",
    "axes[1, 0].set_title('Average Price by Month')\n",
    "axes[1, 0].set_xlabel('Month')\n",
    "axes[1, 0].set_ylabel('Price ($/MWh)')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Price distribution\n",
    "axes[1, 1].hist(df['total_lmp_da'], bins=50, alpha=0.7, edgecolor='black')\n",
    "axes[1, 1].set_title('Price Distribution')\n",
    "axes[1, 1].set_xlabel('Price ($/MWh)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Zone-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze specific zones\n",
    "print(\"Available zones:\")\n",
    "available_zones = df['zone'].dropna().unique()\n",
    "for i, zone in enumerate(available_zones[:10]):  # Show first 10\n",
    "    print(f\"{i+1}. {zone}\")\n",
    "\n",
    "# Select a zone for detailed analysis (you can change this)\n",
    "target_zone = available_zones[0] if len(available_zones) > 0 else None\n",
    "print(f\"\\nAnalyzing zone: {target_zone}\")\n",
    "\n",
    "if target_zone:\n",
    "    zone_data = df[df['zone'] == target_zone].copy()\n",
    "    \n",
    "    # Time series plot for the selected zone\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(zone_data['datetime_beginning_utc'], zone_data['total_lmp_da'], alpha=0.7)\n",
    "    plt.title(f'Price Time Series for {target_zone}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price ($/MWh)')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nStatistics for {target_zone}:\")\n",
    "    print(zone_data['total_lmp_da'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Price Components Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze price components\n",
    "component_cols = ['system_energy_price_da', 'congestion_price_da', 'marginal_loss_price_da']\n",
    "\n",
    "# Check if components exist\n",
    "available_components = [col for col in component_cols if col in df.columns]\n",
    "\n",
    "if available_components:\n",
    "    print(\"=== PRICE COMPONENTS ANALYSIS ===\")\n",
    "    \n",
    "    # Correlation matrix\n",
    "    corr_data = df[['total_lmp_da'] + available_components].corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_data, annot=True, cmap='coolwarm', center=0, \n",
    "                square=True, fmt='.3f')\n",
    "    plt.title('Price Components Correlation Matrix')\n",
    "    plt.show()\n",
    "    \n",
    "    # Component contributions over time\n",
    "    if target_zone:\n",
    "        zone_data = df[df['zone'] == target_zone].copy()\n",
    "        \n",
    "        # Sample data for visualization (take every 24th hour to reduce density)\n",
    "        sample_data = zone_data.iloc[::24].copy()\n",
    "        \n",
    "        plt.figure(figsize=(15, 8))\n",
    "        plt.plot(sample_data['datetime_beginning_utc'], sample_data['total_lmp_da'], \n",
    "                label='Total LMP', linewidth=2)\n",
    "        \n",
    "        if 'system_energy_price_da' in available_components:\n",
    "            plt.plot(sample_data['datetime_beginning_utc'], sample_data['system_energy_price_da'], \n",
    "                    label='Energy Component', alpha=0.7)\n",
    "        if 'congestion_price_da' in available_components:\n",
    "            plt.plot(sample_data['datetime_beginning_utc'], sample_data['congestion_price_da'], \n",
    "                    label='Congestion Component', alpha=0.7)\n",
    "        if 'marginal_loss_price_da' in available_components:\n",
    "            plt.plot(sample_data['datetime_beginning_utc'], sample_data['marginal_loss_price_da'], \n",
    "                    label='Loss Component', alpha=0.7)\n",
    "        \n",
    "        plt.title(f'Price Components Over Time for {target_zone}')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price ($/MWh)')\n",
    "        plt.legend()\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Price component data not available in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run the Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and run the prediction model\n",
    "from pjm_price_prediction import PJMPricePredictor\n",
    "\n",
    "# Initialize predictor\n",
    "predictor = PJMPricePredictor('da_hrl_lmps (1).csv')\n",
    "\n",
    "# Load data (reuse already loaded data to save time)\n",
    "predictor.data = df\n",
    "\n",
    "# Create features\n",
    "print(\"\\nCreating features for modeling...\")\n",
    "feature_df = predictor.create_features(target_zone=target_zone)\n",
    "\n",
    "# Prepare train/test split\n",
    "train_df, test_df = predictor.prepare_train_test(feature_df, test_days=7)\n",
    "\n",
    "# Train models\n",
    "results, best_model = predictor.train_models(train_df, test_df)\n",
    "\n",
    "print(f\"\\nBest performing model: {best_model}\")\n",
    "print(f\"Best MAE: ${results[best_model]['mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed visualizations\n",
    "predictor.create_visualizations(test_df, results)\n",
    "\n",
    "# Additional analysis: Feature importance\n",
    "if 'Random Forest' in results:\n",
    "    rf_model = results['Random Forest']['model']\n",
    "    feature_cols = predictor.scalers['feature_cols']\n",
    "    \n",
    "    # Get feature importance\n",
    "    importance = rf_model.feature_importances_\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'importance': importance\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    # Plot top 15 features\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    top_features = feature_importance.head(15)\n",
    "    plt.barh(range(len(top_features)), top_features['importance'])\n",
    "    plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.title('Top 15 Most Important Features (Random Forest)')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(\"=== PJM PRICE PREDICTION ANALYSIS SUMMARY ===\")\n",
    "print(f\"Dataset: {len(df):,} records\")\n",
    "print(f\"Date range: {df['datetime_beginning_utc'].min()} to {df['datetime_beginning_utc'].max()}\")\n",
    "print(f\"Analyzed zone: {target_zone}\")\n",
    "print(f\"Best model: {best_model}\")\n",
    "print(f\"Best MAE: ${results[best_model]['mae']:.2f}\")\n",
    "print(f\"Best RMSE: ${results[best_model]['rmse']:.2f}\")\n",
    "print(f\"Best RÂ²: {results[best_model]['r2']:.3f}\")\n",
    "\n",
    "print(\"\\n=== RECOMMENDATIONS FOR IMPROVEMENT ===\")\n",
    "print(\"1. Add external data sources:\")\n",
    "print(\"   - Weather forecasts (temperature, wind speed, solar irradiance)\")\n",
    "print(\"   - Load forecasts\")\n",
    "print(\"   - Fuel prices (natural gas, coal)\")\n",
    "print(\"   - Generation outage schedules\")\n",
    "print(\"\\n2. Advanced modeling techniques:\")\n",
    "print(\"   - LSTM/GRU neural networks for sequence modeling\")\n",
    "print(\"   - Ensemble methods combining multiple models\")\n",
    "print(\"   - Transfer learning from similar markets\")\n",
    "print(\"\\n3. Feature engineering:\")\n",
    "print(\"   - Weather-price interaction terms\")\n",
    "print(\"   - Holiday and special event indicators\")\n",
    "print(\"   - Market constraint indicators\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}